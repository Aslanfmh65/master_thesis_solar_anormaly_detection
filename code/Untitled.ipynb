{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import keras\n",
    "from sklearn.utils import resample\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import model_from_json\n",
    "from IPython.display import clear_output\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_case(data, eva_model):\n",
    "    evaluate_cases = {}\n",
    "    for i in range(eva_model):\n",
    "        dataY = [data[ii][-eva_model+i] for ii in range(len(data))]\n",
    "        evaluate_cases[i] = dataY\n",
    "        \n",
    "    return evaluate_cases\n",
    "\n",
    "# Mean Absolute Percentage Error\n",
    "def mean_absolute_percentage_error(data_true, data_predict):\n",
    "    error = 0\n",
    "    count = 0\n",
    "    for i in range(len(data_true)):\n",
    "        if data_true[i] == 0:\n",
    "            continue\n",
    "        error += np.abs((data_true[i]-data_predict[i])/(data_true[i]))\n",
    "        count += 1\n",
    "        \n",
    "    return((error/count)*100)\n",
    "\n",
    "# bootstrapping \n",
    "def bootstrap(dataset, sample_size):\n",
    "    \n",
    "    sample_size = int(len(train)*0.8)\n",
    "    boot = resample(train, replace=True, n_samples=sample_size, random_state=2)\n",
    "    \n",
    "    return boot\n",
    "\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "    dataX, dataY = [],[]\n",
    "    for i in range(len(sequence)):\n",
    "        end_ix = i + n_steps\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        dataX.append(seq_x)\n",
    "        dataY.append(seq_y)\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using only one panel for training the model\n",
    "filename = \"one_week.csv\"\n",
    "dataset = pd.read_csv(filename)\n",
    "dataset = dataset.dropna()\n",
    "dataset = dataset['28563601'].values\n",
    "\n",
    "# # normalize the data\n",
    "# scaler = MinMaxScaler(feature_range=(0,1))\n",
    "# dataset = scaler.fit_transform([dataset])\n",
    "\n",
    "# the number of time steps\n",
    "n_steps = 3\n",
    "\n",
    "# split into samples\n",
    "X, y = split_sequence(dataset, n_steps)\n",
    "\n",
    "# split train and test data\n",
    "trainX, testX, trainY, testY = train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,217\n",
      "Trainable params: 1,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=n_steps, kernel_initializer='he_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Dense(32))\n",
    "# model.add(Activation('relu'))\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))\n",
    "opt = SGD(lr=0.005, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss = 'mean_absolute_error', optimizer=opt)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 450 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "450/450 [==============================] - 0s 393us/step - loss: 101.9458 - val_loss: 48.7516\n",
      "Epoch 2/1000\n",
      "450/450 [==============================] - 0s 46us/step - loss: 47.3124 - val_loss: 132.6875\n",
      "Epoch 3/1000\n",
      "450/450 [==============================] - 0s 41us/step - loss: 93.0195 - val_loss: 47.6101\n",
      "Epoch 4/1000\n",
      "450/450 [==============================] - 0s 43us/step - loss: 44.9013 - val_loss: 47.8862\n",
      "Epoch 5/1000\n",
      "450/450 [==============================] - 0s 41us/step - loss: 44.6085 - val_loss: 47.4763\n",
      "Epoch 6/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5661 - val_loss: 47.5555\n",
      "Epoch 7/1000\n",
      "450/450 [==============================] - 0s 40us/step - loss: 44.7472 - val_loss: 47.4555\n",
      "Epoch 8/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.5845 - val_loss: 47.5765\n",
      "Epoch 9/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.6001 - val_loss: 47.5334\n",
      "Epoch 10/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.7411 - val_loss: 47.5202\n",
      "Epoch 11/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4088 - val_loss: 47.7054\n",
      "Epoch 12/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5110 - val_loss: 47.6046\n",
      "Epoch 13/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4260 - val_loss: 47.5163\n",
      "Epoch 14/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4131 - val_loss: 47.5033\n",
      "Epoch 15/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4202 - val_loss: 47.5096\n",
      "Epoch 16/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4113 - val_loss: 47.5454\n",
      "Epoch 17/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4304 - val_loss: 47.5035\n",
      "Epoch 18/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5034 - val_loss: 47.5357\n",
      "Epoch 19/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5678 - val_loss: 47.5663\n",
      "Epoch 20/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4908 - val_loss: 47.5885\n",
      "Epoch 21/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4343 - val_loss: 47.5075\n",
      "Epoch 22/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.4167 - val_loss: 47.5273\n",
      "Epoch 23/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4374 - val_loss: 47.4989\n",
      "Epoch 24/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.3733 - val_loss: 47.5351\n",
      "Epoch 25/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4053 - val_loss: 47.5167\n",
      "Epoch 26/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4998 - val_loss: 47.5059\n",
      "Epoch 27/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4525 - val_loss: 47.5837\n",
      "Epoch 28/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4043 - val_loss: 47.5558\n",
      "Epoch 29/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5393 - val_loss: 47.6334\n",
      "Epoch 30/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4516 - val_loss: 47.7113\n",
      "Epoch 31/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.5210 - val_loss: 47.5164\n",
      "Epoch 32/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5855 - val_loss: 47.5677\n",
      "Epoch 33/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5189 - val_loss: 47.5674\n",
      "Epoch 34/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.3154 - val_loss: 47.4732\n",
      "Epoch 35/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4185 - val_loss: 47.5239\n",
      "Epoch 36/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.3861 - val_loss: 47.7015\n",
      "Epoch 37/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.5047 - val_loss: 47.6831\n",
      "Epoch 38/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4614 - val_loss: 47.5171\n",
      "Epoch 39/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4361 - val_loss: 47.4737\n",
      "Epoch 40/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.3838 - val_loss: 47.4743\n",
      "Epoch 41/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.6572 - val_loss: 47.4998\n",
      "Epoch 42/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5551 - val_loss: 47.4133\n",
      "Epoch 43/1000\n",
      "450/450 [==============================] - 0s 40us/step - loss: 44.3978 - val_loss: 47.5457\n",
      "Epoch 44/1000\n",
      "450/450 [==============================] - 0s 40us/step - loss: 44.6456 - val_loss: 47.4290\n",
      "Epoch 45/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.3719 - val_loss: 47.5307\n",
      "Epoch 46/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.3719 - val_loss: 47.4386\n",
      "Epoch 47/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.3618 - val_loss: 47.5098\n",
      "Epoch 48/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5033 - val_loss: 47.6349\n",
      "Epoch 49/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4478 - val_loss: 47.4294\n",
      "Epoch 50/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.7427 - val_loss: 47.4419\n",
      "Epoch 51/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.3806 - val_loss: 47.4518\n",
      "Epoch 52/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.3363 - val_loss: 47.5067\n",
      "Epoch 53/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.7220 - val_loss: 47.4274\n",
      "Epoch 54/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5533 - val_loss: 47.4918\n",
      "Epoch 55/1000\n",
      "450/450 [==============================] - 0s 32us/step - loss: 44.4982 - val_loss: 47.4280\n",
      "Epoch 56/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.6046 - val_loss: 47.4257\n",
      "Epoch 57/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.3600 - val_loss: 47.5711\n",
      "Epoch 58/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.3800 - val_loss: 47.5110\n",
      "Epoch 59/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4339 - val_loss: 47.4285\n",
      "Epoch 60/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.3514 - val_loss: 47.4323\n",
      "Epoch 61/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.3469 - val_loss: 47.4198\n",
      "Epoch 62/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4895 - val_loss: 47.5184\n",
      "Epoch 63/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5048 - val_loss: 47.4395\n",
      "Epoch 64/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4687 - val_loss: 47.4500\n",
      "Epoch 65/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.5087 - val_loss: 47.4242\n",
      "Epoch 66/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5009 - val_loss: 47.4338\n",
      "Epoch 67/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.7810 - val_loss: 47.4496\n",
      "Epoch 68/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5165 - val_loss: 47.4329\n",
      "Epoch 69/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4681 - val_loss: 47.4720\n",
      "Epoch 70/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.3743 - val_loss: 47.4766\n",
      "Epoch 71/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5221 - val_loss: 47.4752\n",
      "Epoch 72/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4779 - val_loss: 47.4264\n",
      "Epoch 73/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4925 - val_loss: 47.6018\n",
      "Epoch 74/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5109 - val_loss: 47.4749\n",
      "Epoch 75/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5956 - val_loss: 47.4324\n",
      "Epoch 76/1000\n",
      "450/450 [==============================] - 0s 41us/step - loss: 44.4675 - val_loss: 47.4973\n",
      "Epoch 77/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.6364 - val_loss: 47.4195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.6364 - val_loss: 47.4748\n",
      "Epoch 79/1000\n",
      "450/450 [==============================] - 0s 32us/step - loss: 44.6026 - val_loss: 47.4910\n",
      "Epoch 80/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.3768 - val_loss: 47.4353\n",
      "Epoch 81/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.3501 - val_loss: 47.4849\n",
      "Epoch 82/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.3781 - val_loss: 47.4447\n",
      "Epoch 83/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.3594 - val_loss: 47.4341\n",
      "Epoch 84/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.3482 - val_loss: 47.4758\n",
      "Epoch 85/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.3550 - val_loss: 47.5186\n",
      "Epoch 86/1000\n",
      "450/450 [==============================] - 0s 32us/step - loss: 44.3756 - val_loss: 47.5333\n",
      "Epoch 87/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4327 - val_loss: 47.4160\n",
      "Epoch 88/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.3894 - val_loss: 47.4219\n",
      "Epoch 89/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.3883 - val_loss: 47.4246\n",
      "Epoch 90/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.3614 - val_loss: 47.4437\n",
      "Epoch 91/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4008 - val_loss: 47.5296\n",
      "Epoch 92/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.5063 - val_loss: 47.4351\n",
      "Epoch 93/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4908 - val_loss: 47.4515\n",
      "Epoch 94/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.3755 - val_loss: 47.4812\n",
      "Epoch 95/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.3666 - val_loss: 47.4600\n",
      "Epoch 96/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.3822 - val_loss: 47.4842\n",
      "Epoch 97/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4853 - val_loss: 47.4367\n",
      "Epoch 98/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.3521 - val_loss: 47.4594\n",
      "Epoch 99/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.3777 - val_loss: 47.4839\n",
      "Epoch 100/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.3364 - val_loss: 47.4735\n",
      "Epoch 101/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4607 - val_loss: 47.4531\n",
      "Epoch 102/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.3247 - val_loss: 47.4903\n",
      "Epoch 103/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4285 - val_loss: 47.4601\n",
      "Epoch 104/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.3219 - val_loss: 47.4492\n",
      "Epoch 105/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.3827 - val_loss: 47.5362\n",
      "Epoch 106/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.3963 - val_loss: 47.5002\n",
      "Epoch 107/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.3797 - val_loss: 47.7393\n",
      "Epoch 108/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.5223 - val_loss: 47.4755\n",
      "Epoch 109/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.6445 - val_loss: 47.4574\n",
      "Epoch 110/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4362 - val_loss: 47.5629\n",
      "Epoch 111/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.3647 - val_loss: 47.4438\n",
      "Epoch 112/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4100 - val_loss: 47.5224\n",
      "Epoch 113/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4691 - val_loss: 47.4904\n",
      "Epoch 114/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4258 - val_loss: 47.5247\n",
      "Epoch 115/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.3366 - val_loss: 47.4520\n",
      "Epoch 116/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.7319 - val_loss: 47.4394\n",
      "Epoch 117/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.3331 - val_loss: 47.7054\n",
      "Epoch 118/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4080 - val_loss: 47.4664\n",
      "Epoch 119/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.3937 - val_loss: 47.4641\n",
      "Epoch 120/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.5454 - val_loss: 47.4194\n",
      "Epoch 121/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.3863 - val_loss: 47.4596\n",
      "Epoch 122/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.3737 - val_loss: 47.4338\n",
      "Epoch 123/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.3773 - val_loss: 47.4211\n",
      "Epoch 124/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.3531 - val_loss: 47.4208\n",
      "Epoch 125/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4115 - val_loss: 47.4465\n",
      "Epoch 126/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.6539 - val_loss: 47.4975\n",
      "Epoch 127/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4983 - val_loss: 47.4961\n",
      "Epoch 128/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.3118 - val_loss: 47.4298\n",
      "Epoch 129/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4188 - val_loss: 47.4559\n",
      "Epoch 130/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.3777 - val_loss: 47.4561\n",
      "Epoch 131/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4887 - val_loss: 47.5342\n",
      "Epoch 132/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5374 - val_loss: 47.4229\n",
      "Epoch 133/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.3614 - val_loss: 47.5215\n",
      "Epoch 134/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.5345 - val_loss: 47.4421\n",
      "Epoch 135/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.3357 - val_loss: 47.4298\n",
      "Epoch 136/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4261 - val_loss: 47.4424\n",
      "Epoch 137/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.3429 - val_loss: 47.4540\n",
      "Epoch 138/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.3873 - val_loss: 47.5175\n",
      "Epoch 139/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4021 - val_loss: 47.4383\n",
      "Epoch 140/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.3849 - val_loss: 47.4341\n",
      "Epoch 141/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4575 - val_loss: 47.4383\n",
      "Epoch 142/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4935 - val_loss: 47.4539\n",
      "Epoch 143/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.3442 - val_loss: 47.4413\n",
      "Epoch 144/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.3668 - val_loss: 47.4409\n",
      "Epoch 145/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.5086 - val_loss: 47.4612\n",
      "Epoch 146/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4471 - val_loss: 47.4364\n",
      "Epoch 147/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.3309 - val_loss: 47.5588\n",
      "Epoch 148/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.3943 - val_loss: 47.5416\n",
      "Epoch 149/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4337 - val_loss: 47.4328\n",
      "Epoch 150/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4211 - val_loss: 47.4292\n",
      "Epoch 151/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4613 - val_loss: 47.5560\n",
      "Epoch 152/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.3969 - val_loss: 47.4541\n",
      "Epoch 153/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.3307 - val_loss: 47.5898\n",
      "Epoch 154/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.3635 - val_loss: 47.4729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.3359 - val_loss: 47.4460\n",
      "Epoch 156/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.3493 - val_loss: 47.4657\n",
      "Epoch 157/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4164 - val_loss: 47.4651\n",
      "Epoch 158/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.3577 - val_loss: 47.4291\n",
      "Epoch 159/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.3406 - val_loss: 47.4254\n",
      "Epoch 160/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.3617 - val_loss: 47.4580\n",
      "Epoch 161/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.3856 - val_loss: 47.4330\n",
      "Epoch 162/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4862 - val_loss: 47.4690\n",
      "Epoch 163/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4151 - val_loss: 47.4234\n",
      "Epoch 164/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.3316 - val_loss: 47.4239\n",
      "Epoch 165/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4458 - val_loss: 47.4335\n",
      "Epoch 166/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.3500 - val_loss: 47.4258\n",
      "Epoch 167/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4862 - val_loss: 47.4240\n",
      "Epoch 168/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.3583 - val_loss: 47.5301\n",
      "Epoch 169/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.3203 - val_loss: 47.4395\n",
      "Epoch 170/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.5098 - val_loss: 47.4373\n",
      "Epoch 171/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4957 - val_loss: 47.4828\n",
      "Epoch 172/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.3787 - val_loss: 47.4736\n",
      "Epoch 173/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.3993 - val_loss: 47.6749\n",
      "Epoch 174/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.5499 - val_loss: 47.4747\n",
      "Epoch 175/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4484 - val_loss: 47.4688\n",
      "Epoch 176/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.6176 - val_loss: 47.5199\n",
      "Epoch 177/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4757 - val_loss: 47.4299\n",
      "Epoch 178/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.3797 - val_loss: 47.4697\n",
      "Epoch 179/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.3577 - val_loss: 47.4425\n",
      "Epoch 180/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.3325 - val_loss: 47.4439\n",
      "Epoch 181/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4682 - val_loss: 47.4414\n",
      "Epoch 182/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.3326 - val_loss: 47.4377\n",
      "Epoch 183/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.3947 - val_loss: 47.4543\n",
      "Epoch 184/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4800 - val_loss: 47.5271\n",
      "Epoch 185/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4203 - val_loss: 47.4365\n",
      "Epoch 186/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.3690 - val_loss: 47.5869\n",
      "Epoch 187/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.3661 - val_loss: 47.4495\n",
      "Epoch 188/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4498 - val_loss: 47.4481\n",
      "Epoch 189/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4090 - val_loss: 47.7120\n",
      "Epoch 190/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5075 - val_loss: 47.6222\n",
      "Epoch 191/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4108 - val_loss: 47.5781\n",
      "Epoch 192/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.3954 - val_loss: 47.5383\n",
      "Epoch 193/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4322 - val_loss: 47.4517\n",
      "Epoch 194/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4244 - val_loss: 47.4616\n",
      "Epoch 195/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.2764 - val_loss: 47.3595\n",
      "Epoch 196/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.3190 - val_loss: 47.1492\n",
      "Epoch 197/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 43.9454 - val_loss: 45.4947\n",
      "Epoch 198/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 35.5705 - val_loss: 16.5254\n",
      "Epoch 199/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.7657 - val_loss: 47.5197\n",
      "Epoch 200/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4960 - val_loss: 47.6700\n",
      "Epoch 201/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5593 - val_loss: 47.5559\n",
      "Epoch 202/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4912 - val_loss: 47.5435\n",
      "Epoch 203/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.7110 - val_loss: 47.6017\n",
      "Epoch 204/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5656 - val_loss: 47.5531\n",
      "Epoch 205/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5150 - val_loss: 47.6049\n",
      "Epoch 206/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5738 - val_loss: 47.7763\n",
      "Epoch 207/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5556 - val_loss: 47.5790\n",
      "Epoch 208/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4432 - val_loss: 47.5131\n",
      "Epoch 209/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5082 - val_loss: 47.5274\n",
      "Epoch 210/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4372 - val_loss: 47.5260\n",
      "Epoch 211/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4636 - val_loss: 47.5278\n",
      "Epoch 212/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5618 - val_loss: 47.5267\n",
      "Epoch 213/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5569 - val_loss: 47.5875\n",
      "Epoch 214/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4770 - val_loss: 47.5618\n",
      "Epoch 215/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.5308 - val_loss: 47.7690\n",
      "Epoch 216/1000\n",
      "450/450 [==============================] - 0s 40us/step - loss: 44.5514 - val_loss: 47.6940\n",
      "Epoch 217/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.5064 - val_loss: 47.5308\n",
      "Epoch 218/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.5860 - val_loss: 47.6139\n",
      "Epoch 219/1000\n",
      "450/450 [==============================] - 0s 40us/step - loss: 44.6026 - val_loss: 47.5242\n",
      "Epoch 220/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4907 - val_loss: 47.5131\n",
      "Epoch 221/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4696 - val_loss: 47.5187\n",
      "Epoch 222/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.5059 - val_loss: 47.6707\n",
      "Epoch 223/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.6112 - val_loss: 47.5431\n",
      "Epoch 224/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4982 - val_loss: 47.5316\n",
      "Epoch 225/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4665 - val_loss: 47.5266\n",
      "Epoch 226/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4344 - val_loss: 47.6060\n",
      "Epoch 227/1000\n",
      "450/450 [==============================] - 0s 40us/step - loss: 44.4761 - val_loss: 47.5174\n",
      "Epoch 228/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.6229 - val_loss: 47.5395\n",
      "Epoch 229/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4473 - val_loss: 47.6056\n",
      "Epoch 230/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.4526 - val_loss: 47.5814\n",
      "Epoch 231/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 0s 37us/step - loss: 44.4419 - val_loss: 47.5227\n",
      "Epoch 232/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.6035 - val_loss: 47.5149\n",
      "Epoch 233/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4235 - val_loss: 47.6403\n",
      "Epoch 234/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.6166 - val_loss: 47.5902\n",
      "Epoch 235/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4669 - val_loss: 47.5517\n",
      "Epoch 236/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4828 - val_loss: 47.7073\n",
      "Epoch 237/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5311 - val_loss: 47.5571\n",
      "Epoch 238/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4499 - val_loss: 47.5171\n",
      "Epoch 239/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4669 - val_loss: 47.5529\n",
      "Epoch 240/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4270 - val_loss: 47.7167\n",
      "Epoch 241/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4697 - val_loss: 47.5364\n",
      "Epoch 242/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4751 - val_loss: 47.5851\n",
      "Epoch 243/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.6399 - val_loss: 47.6786\n",
      "Epoch 244/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4849 - val_loss: 47.5230\n",
      "Epoch 245/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5297 - val_loss: 47.5416\n",
      "Epoch 246/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.5633 - val_loss: 47.5316\n",
      "Epoch 247/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4450 - val_loss: 47.5536\n",
      "Epoch 248/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4554 - val_loss: 47.5521\n",
      "Epoch 249/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.6905 - val_loss: 47.5201\n",
      "Epoch 250/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4921 - val_loss: 47.6599\n",
      "Epoch 251/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.5579 - val_loss: 47.5814\n",
      "Epoch 252/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5475 - val_loss: 47.5482\n",
      "Epoch 253/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4906 - val_loss: 47.5186\n",
      "Epoch 254/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5285 - val_loss: 47.5367\n",
      "Epoch 255/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4861 - val_loss: 47.5826\n",
      "Epoch 256/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4940 - val_loss: 47.7142\n",
      "Epoch 257/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5834 - val_loss: 47.5330\n",
      "Epoch 258/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5227 - val_loss: 47.5163\n",
      "Epoch 259/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4328 - val_loss: 47.5278\n",
      "Epoch 260/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5175 - val_loss: 47.5789\n",
      "Epoch 261/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5654 - val_loss: 47.5113\n",
      "Epoch 262/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4507 - val_loss: 47.5296\n",
      "Epoch 263/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4947 - val_loss: 47.5246\n",
      "Epoch 264/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4732 - val_loss: 47.5131\n",
      "Epoch 265/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4411 - val_loss: 47.5347\n",
      "Epoch 266/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4542 - val_loss: 47.5974\n",
      "Epoch 267/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5430 - val_loss: 47.6040\n",
      "Epoch 268/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4916 - val_loss: 47.5275\n",
      "Epoch 269/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4503 - val_loss: 47.5166\n",
      "Epoch 270/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4691 - val_loss: 47.5447\n",
      "Epoch 271/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4485 - val_loss: 47.5185\n",
      "Epoch 272/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4756 - val_loss: 47.5542\n",
      "Epoch 273/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4838 - val_loss: 47.5922\n",
      "Epoch 274/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5591 - val_loss: 47.5521\n",
      "Epoch 275/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5181 - val_loss: 47.6195\n",
      "Epoch 276/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4935 - val_loss: 47.5804\n",
      "Epoch 277/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5032 - val_loss: 47.6624\n",
      "Epoch 278/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.7476 - val_loss: 47.6030\n",
      "Epoch 279/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4548 - val_loss: 47.6547\n",
      "Epoch 280/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5249 - val_loss: 47.5667\n",
      "Epoch 281/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4511 - val_loss: 47.5329\n",
      "Epoch 282/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4923 - val_loss: 47.5359\n",
      "Epoch 283/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4782 - val_loss: 47.6568\n",
      "Epoch 284/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4652 - val_loss: 47.5946\n",
      "Epoch 285/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4662 - val_loss: 47.6790\n",
      "Epoch 286/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4444 - val_loss: 47.5293\n",
      "Epoch 287/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4669 - val_loss: 47.5180\n",
      "Epoch 288/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5014 - val_loss: 47.5254\n",
      "Epoch 289/1000\n",
      "450/450 [==============================] - 0s 32us/step - loss: 44.4499 - val_loss: 47.6554\n",
      "Epoch 290/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.6305 - val_loss: 47.5983\n",
      "Epoch 291/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5488 - val_loss: 47.5128\n",
      "Epoch 292/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4494 - val_loss: 47.5428\n",
      "Epoch 293/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4449 - val_loss: 47.6458\n",
      "Epoch 294/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4955 - val_loss: 47.6742\n",
      "Epoch 295/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5518 - val_loss: 47.7022\n",
      "Epoch 296/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5555 - val_loss: 47.5608\n",
      "Epoch 297/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4425 - val_loss: 47.5367\n",
      "Epoch 298/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4552 - val_loss: 47.5847\n",
      "Epoch 299/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5004 - val_loss: 47.7167\n",
      "Epoch 300/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4171 - val_loss: 47.5148\n",
      "Epoch 301/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5597 - val_loss: 47.5242\n",
      "Epoch 302/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5243 - val_loss: 47.5118\n",
      "Epoch 303/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4536 - val_loss: 47.5417\n",
      "Epoch 304/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4624 - val_loss: 47.5191\n",
      "Epoch 305/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.5658 - val_loss: 47.5417\n",
      "Epoch 306/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4817 - val_loss: 47.5277\n",
      "Epoch 307/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 0s 35us/step - loss: 44.5240 - val_loss: 47.5219\n",
      "Epoch 308/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5448 - val_loss: 47.6785\n",
      "Epoch 309/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4848 - val_loss: 47.5490\n",
      "Epoch 310/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.5084 - val_loss: 47.5189\n",
      "Epoch 311/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4583 - val_loss: 47.7864\n",
      "Epoch 312/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.6620 - val_loss: 47.6892\n",
      "Epoch 313/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5118 - val_loss: 47.5188\n",
      "Epoch 314/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5593 - val_loss: 47.5997\n",
      "Epoch 315/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5725 - val_loss: 47.5117\n",
      "Epoch 316/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5380 - val_loss: 47.5297\n",
      "Epoch 317/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4580 - val_loss: 47.5458\n",
      "Epoch 318/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5073 - val_loss: 47.5731\n",
      "Epoch 319/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.7339 - val_loss: 47.7869\n",
      "Epoch 320/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5426 - val_loss: 47.5285\n",
      "Epoch 321/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4296 - val_loss: 47.5223\n",
      "Epoch 322/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.5001 - val_loss: 47.5196\n",
      "Epoch 323/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4743 - val_loss: 47.5195\n",
      "Epoch 324/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5044 - val_loss: 47.5184\n",
      "Epoch 325/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.6782 - val_loss: 47.5157\n",
      "Epoch 326/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4154 - val_loss: 47.9420\n",
      "Epoch 327/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.7418 - val_loss: 47.6041\n",
      "Epoch 328/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4938 - val_loss: 47.5611\n",
      "Epoch 329/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4521 - val_loss: 47.5458\n",
      "Epoch 330/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4433 - val_loss: 47.5465\n",
      "Epoch 331/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4400 - val_loss: 47.5921\n",
      "Epoch 332/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5271 - val_loss: 47.6383\n",
      "Epoch 333/1000\n",
      "450/450 [==============================] - 0s 32us/step - loss: 44.4765 - val_loss: 47.5147\n",
      "Epoch 334/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5555 - val_loss: 47.5144\n",
      "Epoch 335/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4684 - val_loss: 47.6683\n",
      "Epoch 336/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4466 - val_loss: 47.5147\n",
      "Epoch 337/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.6046 - val_loss: 47.5387\n",
      "Epoch 338/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4830 - val_loss: 47.5957\n",
      "Epoch 339/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5601 - val_loss: 47.6021\n",
      "Epoch 340/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4423 - val_loss: 47.5126\n",
      "Epoch 341/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4425 - val_loss: 47.5262\n",
      "Epoch 342/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4343 - val_loss: 47.5474\n",
      "Epoch 343/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4538 - val_loss: 47.6232\n",
      "Epoch 344/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5806 - val_loss: 47.5447\n",
      "Epoch 345/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4663 - val_loss: 47.5212\n",
      "Epoch 346/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4526 - val_loss: 47.5957\n",
      "Epoch 347/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4514 - val_loss: 47.6157\n",
      "Epoch 348/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4971 - val_loss: 47.5240\n",
      "Epoch 349/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4320 - val_loss: 47.5395\n",
      "Epoch 350/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.5350 - val_loss: 47.5838\n",
      "Epoch 351/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4659 - val_loss: 47.6498\n",
      "Epoch 352/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4474 - val_loss: 47.5392\n",
      "Epoch 353/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4603 - val_loss: 47.5115\n",
      "Epoch 354/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.5670 - val_loss: 47.5134\n",
      "Epoch 355/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4235 - val_loss: 47.6525\n",
      "Epoch 356/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5392 - val_loss: 47.5585\n",
      "Epoch 357/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4762 - val_loss: 47.5155\n",
      "Epoch 358/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5209 - val_loss: 47.5465\n",
      "Epoch 359/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4840 - val_loss: 47.6235\n",
      "Epoch 360/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.6477 - val_loss: 47.5156\n",
      "Epoch 361/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4582 - val_loss: 47.6828\n",
      "Epoch 362/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4429 - val_loss: 47.5162\n",
      "Epoch 363/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4637 - val_loss: 47.5181\n",
      "Epoch 364/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4247 - val_loss: 47.5382\n",
      "Epoch 365/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4844 - val_loss: 47.5258\n",
      "Epoch 366/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4471 - val_loss: 47.5616\n",
      "Epoch 367/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4684 - val_loss: 47.6025\n",
      "Epoch 368/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4398 - val_loss: 47.5365\n",
      "Epoch 369/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4597 - val_loss: 47.5168\n",
      "Epoch 370/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.5576 - val_loss: 47.5318\n",
      "Epoch 371/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5503 - val_loss: 47.5551\n",
      "Epoch 372/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4656 - val_loss: 47.5698\n",
      "Epoch 373/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4568 - val_loss: 47.6965\n",
      "Epoch 374/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5133 - val_loss: 47.5915\n",
      "Epoch 375/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4417 - val_loss: 47.5199\n",
      "Epoch 376/1000\n",
      "450/450 [==============================] - 0s 41us/step - loss: 44.4622 - val_loss: 47.5136\n",
      "Epoch 377/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5288 - val_loss: 47.5458\n",
      "Epoch 378/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5358 - val_loss: 47.5250\n",
      "Epoch 379/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.6650 - val_loss: 47.5524\n",
      "Epoch 380/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.5823 - val_loss: 47.6022\n",
      "Epoch 381/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4770 - val_loss: 47.6170\n",
      "Epoch 382/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4624 - val_loss: 47.5174\n",
      "Epoch 383/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 0s 35us/step - loss: 44.5307 - val_loss: 47.5134\n",
      "Epoch 384/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4245 - val_loss: 47.7539\n",
      "Epoch 385/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.7062 - val_loss: 47.5731\n",
      "Epoch 386/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.6251 - val_loss: 47.5308\n",
      "Epoch 387/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5917 - val_loss: 47.5490\n",
      "Epoch 388/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4379 - val_loss: 47.5132\n",
      "Epoch 389/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4901 - val_loss: 47.6012\n",
      "Epoch 390/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4431 - val_loss: 47.5375\n",
      "Epoch 391/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4793 - val_loss: 47.5157\n",
      "Epoch 392/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.7078 - val_loss: 47.5110\n",
      "Epoch 393/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.4708 - val_loss: 47.5703\n",
      "Epoch 394/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4727 - val_loss: 47.5124\n",
      "Epoch 395/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4770 - val_loss: 47.5828\n",
      "Epoch 396/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.5226 - val_loss: 47.5879\n",
      "Epoch 397/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4480 - val_loss: 47.5441\n",
      "Epoch 398/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5499 - val_loss: 47.5501\n",
      "Epoch 399/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4908 - val_loss: 47.5814\n",
      "Epoch 400/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.6136 - val_loss: 47.5530\n",
      "Epoch 401/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.5356 - val_loss: 47.5484\n",
      "Epoch 402/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5378 - val_loss: 47.6499\n",
      "Epoch 403/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4526 - val_loss: 47.5861\n",
      "Epoch 404/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4735 - val_loss: 47.6608\n",
      "Epoch 405/1000\n",
      "450/450 [==============================] - 0s 40us/step - loss: 44.5199 - val_loss: 47.5617\n",
      "Epoch 406/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4904 - val_loss: 47.5131\n",
      "Epoch 407/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4285 - val_loss: 47.6025\n",
      "Epoch 408/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4675 - val_loss: 47.5902\n",
      "Epoch 409/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4361 - val_loss: 47.5624\n",
      "Epoch 410/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5116 - val_loss: 47.6839\n",
      "Epoch 411/1000\n",
      "450/450 [==============================] - 0s 31us/step - loss: 44.5111 - val_loss: 47.5999\n",
      "Epoch 412/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4691 - val_loss: 47.5188\n",
      "Epoch 413/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4770 - val_loss: 47.5435\n",
      "Epoch 414/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.5905 - val_loss: 47.5257\n",
      "Epoch 415/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4872 - val_loss: 47.8038\n",
      "Epoch 416/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.5519 - val_loss: 47.5394\n",
      "Epoch 417/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4430 - val_loss: 47.5440\n",
      "Epoch 418/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4981 - val_loss: 47.5329\n",
      "Epoch 419/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4542 - val_loss: 47.5167\n",
      "Epoch 420/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4445 - val_loss: 47.5268\n",
      "Epoch 421/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4586 - val_loss: 47.5445\n",
      "Epoch 422/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4962 - val_loss: 47.5124\n",
      "Epoch 423/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4559 - val_loss: 47.7943\n",
      "Epoch 424/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5976 - val_loss: 47.5372\n",
      "Epoch 425/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.7428 - val_loss: 47.5148\n",
      "Epoch 426/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.3919 - val_loss: 47.7873\n",
      "Epoch 427/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.6346 - val_loss: 47.6677\n",
      "Epoch 428/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4577 - val_loss: 47.5317\n",
      "Epoch 429/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4471 - val_loss: 47.6297\n",
      "Epoch 430/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4505 - val_loss: 47.5328\n",
      "Epoch 431/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5384 - val_loss: 47.5639\n",
      "Epoch 432/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.5587 - val_loss: 47.5125\n",
      "Epoch 433/1000\n",
      "450/450 [==============================] - 0s 41us/step - loss: 44.4346 - val_loss: 47.5401\n",
      "Epoch 434/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4831 - val_loss: 47.5964\n",
      "Epoch 435/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4371 - val_loss: 47.5138\n",
      "Epoch 436/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.6105 - val_loss: 47.5259\n",
      "Epoch 437/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.6684 - val_loss: 47.6449\n",
      "Epoch 438/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4266 - val_loss: 47.5157\n",
      "Epoch 439/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.6190 - val_loss: 47.5477\n",
      "Epoch 440/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4475 - val_loss: 47.6337\n",
      "Epoch 441/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.6246 - val_loss: 47.5834\n",
      "Epoch 442/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5143 - val_loss: 47.5868\n",
      "Epoch 443/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.6634 - val_loss: 47.5162\n",
      "Epoch 444/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5881 - val_loss: 47.6940\n",
      "Epoch 445/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4468 - val_loss: 47.5196\n",
      "Epoch 446/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4736 - val_loss: 47.5133\n",
      "Epoch 447/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4846 - val_loss: 47.5232\n",
      "Epoch 448/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4760 - val_loss: 47.5195\n",
      "Epoch 449/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4507 - val_loss: 47.5560\n",
      "Epoch 450/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4486 - val_loss: 47.5878\n",
      "Epoch 451/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4419 - val_loss: 47.5597\n",
      "Epoch 452/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4391 - val_loss: 47.5168\n",
      "Epoch 453/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4785 - val_loss: 47.5237\n",
      "Epoch 454/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4844 - val_loss: 47.5818\n",
      "Epoch 455/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5126 - val_loss: 47.7521\n",
      "Epoch 456/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5313 - val_loss: 47.5557\n",
      "Epoch 457/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4590 - val_loss: 47.5175\n",
      "Epoch 458/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4156 - val_loss: 47.5817\n",
      "Epoch 459/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 0s 38us/step - loss: 44.4631 - val_loss: 47.5133\n",
      "Epoch 460/1000\n",
      "450/450 [==============================] - 0s 40us/step - loss: 44.4611 - val_loss: 47.5197\n",
      "Epoch 461/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4290 - val_loss: 47.5396\n",
      "Epoch 462/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4471 - val_loss: 47.5150\n",
      "Epoch 463/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.5340 - val_loss: 47.5477\n",
      "Epoch 464/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5375 - val_loss: 47.8214\n",
      "Epoch 465/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5809 - val_loss: 47.5760\n",
      "Epoch 466/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4421 - val_loss: 47.5506\n",
      "Epoch 467/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4361 - val_loss: 47.6897\n",
      "Epoch 468/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.6028 - val_loss: 47.6783\n",
      "Epoch 469/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4588 - val_loss: 47.6287\n",
      "Epoch 470/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4704 - val_loss: 47.5870\n",
      "Epoch 471/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4977 - val_loss: 47.5438\n",
      "Epoch 472/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4322 - val_loss: 47.5197\n",
      "Epoch 473/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.5074 - val_loss: 47.5214\n",
      "Epoch 474/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4762 - val_loss: 47.5560\n",
      "Epoch 475/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4530 - val_loss: 47.6160\n",
      "Epoch 476/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.4910 - val_loss: 47.5162\n",
      "Epoch 477/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4647 - val_loss: 47.5267\n",
      "Epoch 478/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4800 - val_loss: 47.5517\n",
      "Epoch 479/1000\n",
      "450/450 [==============================] - 0s 41us/step - loss: 44.4813 - val_loss: 47.7172\n",
      "Epoch 480/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.5594 - val_loss: 47.5814\n",
      "Epoch 481/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4426 - val_loss: 47.5119\n",
      "Epoch 482/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4703 - val_loss: 47.5354\n",
      "Epoch 483/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4373 - val_loss: 47.6042\n",
      "Epoch 484/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5187 - val_loss: 47.5817\n",
      "Epoch 485/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4417 - val_loss: 47.5160\n",
      "Epoch 486/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5118 - val_loss: 47.5746\n",
      "Epoch 487/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5033 - val_loss: 47.5156\n",
      "Epoch 488/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.4575 - val_loss: 47.5770\n",
      "Epoch 489/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4232 - val_loss: 47.5178\n",
      "Epoch 490/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4840 - val_loss: 47.5818\n",
      "Epoch 491/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4662 - val_loss: 47.5142\n",
      "Epoch 492/1000\n",
      "450/450 [==============================] - 0s 42us/step - loss: 44.6159 - val_loss: 47.5250\n",
      "Epoch 493/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.4651 - val_loss: 47.5208\n",
      "Epoch 494/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5051 - val_loss: 47.5271\n",
      "Epoch 495/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5248 - val_loss: 47.5319\n",
      "Epoch 496/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.6788 - val_loss: 47.5587\n",
      "Epoch 497/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.5594 - val_loss: 47.5137\n",
      "Epoch 498/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4768 - val_loss: 47.6096\n",
      "Epoch 499/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4525 - val_loss: 47.6003\n",
      "Epoch 500/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4912 - val_loss: 47.5568\n",
      "Epoch 501/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.3773 - val_loss: 47.5251\n",
      "Epoch 502/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5182 - val_loss: 47.5172\n",
      "Epoch 503/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4406 - val_loss: 47.5455\n",
      "Epoch 504/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4340 - val_loss: 47.6698\n",
      "Epoch 505/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4893 - val_loss: 47.6069\n",
      "Epoch 506/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4266 - val_loss: 47.5407\n",
      "Epoch 507/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4815 - val_loss: 47.7381\n",
      "Epoch 508/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5301 - val_loss: 47.6918\n",
      "Epoch 509/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.5461 - val_loss: 47.5597\n",
      "Epoch 510/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4799 - val_loss: 47.5351\n",
      "Epoch 511/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4790 - val_loss: 47.5213\n",
      "Epoch 512/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4419 - val_loss: 47.5458\n",
      "Epoch 513/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4551 - val_loss: 47.6055\n",
      "Epoch 514/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4471 - val_loss: 47.5490\n",
      "Epoch 515/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4406 - val_loss: 47.5419\n",
      "Epoch 516/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4702 - val_loss: 47.5206\n",
      "Epoch 517/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4382 - val_loss: 47.5273\n",
      "Epoch 518/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4109 - val_loss: 47.5951\n",
      "Epoch 519/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4460 - val_loss: 47.5770\n",
      "Epoch 520/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4417 - val_loss: 47.5511\n",
      "Epoch 521/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5082 - val_loss: 47.6051\n",
      "Epoch 522/1000\n",
      "450/450 [==============================] - 0s 43us/step - loss: 44.4401 - val_loss: 47.5249\n",
      "Epoch 523/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4934 - val_loss: 47.5387\n",
      "Epoch 524/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4738 - val_loss: 47.5169\n",
      "Epoch 525/1000\n",
      "450/450 [==============================] - 0s 40us/step - loss: 44.4619 - val_loss: 47.5159\n",
      "Epoch 526/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4493 - val_loss: 47.5325\n",
      "Epoch 527/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4519 - val_loss: 47.5217\n",
      "Epoch 528/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4240 - val_loss: 47.5257\n",
      "Epoch 529/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4901 - val_loss: 47.5164\n",
      "Epoch 530/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.4411 - val_loss: 47.5209\n",
      "Epoch 531/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.4833 - val_loss: 47.5220\n",
      "Epoch 532/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4383 - val_loss: 47.5326\n",
      "Epoch 533/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5055 - val_loss: 47.5265\n",
      "Epoch 534/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.6333 - val_loss: 47.5277\n",
      "Epoch 535/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 0s 37us/step - loss: 44.4344 - val_loss: 47.6962\n",
      "Epoch 536/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4729 - val_loss: 47.5553\n",
      "Epoch 537/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5144 - val_loss: 47.5143\n",
      "Epoch 538/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4742 - val_loss: 47.5758\n",
      "Epoch 539/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.4444 - val_loss: 47.5528\n",
      "Epoch 540/1000\n",
      "450/450 [==============================] - 0s 42us/step - loss: 44.4602 - val_loss: 47.5204\n",
      "Epoch 541/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4179 - val_loss: 47.5918\n",
      "Epoch 542/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5785 - val_loss: 47.6836\n",
      "Epoch 543/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4671 - val_loss: 47.5715\n",
      "Epoch 544/1000\n",
      "450/450 [==============================] - 0s 30us/step - loss: 44.4398 - val_loss: 47.5620\n",
      "Epoch 545/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4440 - val_loss: 47.6168\n",
      "Epoch 546/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4428 - val_loss: 47.5470\n",
      "Epoch 547/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4778 - val_loss: 47.5199\n",
      "Epoch 548/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4392 - val_loss: 47.5475\n",
      "Epoch 549/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4441 - val_loss: 47.5979\n",
      "Epoch 550/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4652 - val_loss: 47.6918\n",
      "Epoch 551/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4776 - val_loss: 47.6444\n",
      "Epoch 552/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4678 - val_loss: 47.5470\n",
      "Epoch 553/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4117 - val_loss: 47.5519\n",
      "Epoch 554/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.6034 - val_loss: 47.5460\n",
      "Epoch 555/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4766 - val_loss: 47.5745\n",
      "Epoch 556/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4872 - val_loss: 47.7508\n",
      "Epoch 557/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.5224 - val_loss: 47.5853\n",
      "Epoch 558/1000\n",
      "450/450 [==============================] - 0s 31us/step - loss: 44.4913 - val_loss: 47.5163\n",
      "Epoch 559/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.5105 - val_loss: 47.5189\n",
      "Epoch 560/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.5643 - val_loss: 47.5767\n",
      "Epoch 561/1000\n",
      "450/450 [==============================] - 0s 32us/step - loss: 44.4250 - val_loss: 47.5089\n",
      "Epoch 562/1000\n",
      "450/450 [==============================] - 0s 31us/step - loss: 44.4781 - val_loss: 47.5211\n",
      "Epoch 563/1000\n",
      "450/450 [==============================] - 0s 42us/step - loss: 44.5088 - val_loss: 47.5173\n",
      "Epoch 564/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.5005 - val_loss: 47.5121\n",
      "Epoch 565/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4560 - val_loss: 47.5317\n",
      "Epoch 566/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4306 - val_loss: 47.6308\n",
      "Epoch 567/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4891 - val_loss: 47.6771\n",
      "Epoch 568/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4860 - val_loss: 47.5456\n",
      "Epoch 569/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4274 - val_loss: 47.5853\n",
      "Epoch 570/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4349 - val_loss: 47.6636\n",
      "Epoch 571/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4932 - val_loss: 47.5257\n",
      "Epoch 572/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4628 - val_loss: 47.5570\n",
      "Epoch 573/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5884 - val_loss: 47.5201\n",
      "Epoch 574/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4150 - val_loss: 47.7027\n",
      "Epoch 575/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4820 - val_loss: 47.6056\n",
      "Epoch 576/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4644 - val_loss: 47.5698\n",
      "Epoch 577/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4780 - val_loss: 47.5706\n",
      "Epoch 578/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4433 - val_loss: 47.6891\n",
      "Epoch 579/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4651 - val_loss: 47.6211\n",
      "Epoch 580/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.5033 - val_loss: 47.5824\n",
      "Epoch 581/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4505 - val_loss: 47.5108\n",
      "Epoch 582/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5072 - val_loss: 47.5100\n",
      "Epoch 583/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.3926 - val_loss: 47.7117\n",
      "Epoch 584/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.6018 - val_loss: 47.6483\n",
      "Epoch 585/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4499 - val_loss: 47.5263\n",
      "Epoch 586/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4356 - val_loss: 47.5369\n",
      "Epoch 587/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4369 - val_loss: 47.5176\n",
      "Epoch 588/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4525 - val_loss: 47.5419\n",
      "Epoch 589/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4283 - val_loss: 47.5601\n",
      "Epoch 590/1000\n",
      "450/450 [==============================] - 0s 41us/step - loss: 44.4698 - val_loss: 47.5607\n",
      "Epoch 591/1000\n",
      "450/450 [==============================] - 0s 41us/step - loss: 44.4316 - val_loss: 47.5265\n",
      "Epoch 592/1000\n",
      "450/450 [==============================] - 0s 41us/step - loss: 44.4298 - val_loss: 47.5146\n",
      "Epoch 593/1000\n",
      "450/450 [==============================] - 0s 43us/step - loss: 44.4379 - val_loss: 47.5680\n",
      "Epoch 594/1000\n",
      "450/450 [==============================] - 0s 41us/step - loss: 44.5207 - val_loss: 47.7361\n",
      "Epoch 595/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.5333 - val_loss: 47.5964\n",
      "Epoch 596/1000\n",
      "450/450 [==============================] - 0s 41us/step - loss: 44.4319 - val_loss: 47.5394\n",
      "Epoch 597/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4410 - val_loss: 47.6494\n",
      "Epoch 598/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5372 - val_loss: 47.7402\n",
      "Epoch 599/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.5075 - val_loss: 47.6002\n",
      "Epoch 600/1000\n",
      "450/450 [==============================] - 0s 40us/step - loss: 44.4454 - val_loss: 47.5356\n",
      "Epoch 601/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4409 - val_loss: 47.5399\n",
      "Epoch 602/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.4278 - val_loss: 47.5347\n",
      "Epoch 603/1000\n",
      "450/450 [==============================] - 0s 42us/step - loss: 44.4301 - val_loss: 47.5517\n",
      "Epoch 604/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.4541 - val_loss: 47.7025\n",
      "Epoch 605/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5659 - val_loss: 47.6336\n",
      "Epoch 606/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4888 - val_loss: 47.5482\n",
      "Epoch 607/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4157 - val_loss: 47.6594\n",
      "Epoch 608/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4979 - val_loss: 47.6286\n",
      "Epoch 609/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4671 - val_loss: 47.7082\n",
      "Epoch 610/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5497 - val_loss: 47.7151\n",
      "Epoch 611/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 0s 35us/step - loss: 44.5051 - val_loss: 47.5191\n",
      "Epoch 612/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4870 - val_loss: 47.5253\n",
      "Epoch 613/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4644 - val_loss: 47.5203\n",
      "Epoch 614/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4298 - val_loss: 47.5140\n",
      "Epoch 615/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5194 - val_loss: 47.5317\n",
      "Epoch 616/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4947 - val_loss: 47.5199\n",
      "Epoch 617/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4585 - val_loss: 47.5177\n",
      "Epoch 618/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4643 - val_loss: 47.5257\n",
      "Epoch 619/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4509 - val_loss: 47.5477\n",
      "Epoch 620/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4320 - val_loss: 47.6210\n",
      "Epoch 621/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4407 - val_loss: 47.5501\n",
      "Epoch 622/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.4574 - val_loss: 47.5144\n",
      "Epoch 623/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4418 - val_loss: 47.5118\n",
      "Epoch 624/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4476 - val_loss: 47.5416\n",
      "Epoch 625/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.5026 - val_loss: 47.6516\n",
      "Epoch 626/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4615 - val_loss: 47.5579\n",
      "Epoch 627/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4523 - val_loss: 47.6609\n",
      "Epoch 628/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5677 - val_loss: 47.6284\n",
      "Epoch 629/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4218 - val_loss: 47.5133\n",
      "Epoch 630/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5313 - val_loss: 47.5445\n",
      "Epoch 631/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4810 - val_loss: 47.5149\n",
      "Epoch 632/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4718 - val_loss: 47.6680\n",
      "Epoch 633/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5355 - val_loss: 47.7237\n",
      "Epoch 634/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5058 - val_loss: 47.5955\n",
      "Epoch 635/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4576 - val_loss: 47.5548\n",
      "Epoch 636/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4381 - val_loss: 47.5315\n",
      "Epoch 637/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4290 - val_loss: 47.5169\n",
      "Epoch 638/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5199 - val_loss: 47.5206\n",
      "Epoch 639/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.4462 - val_loss: 47.5359\n",
      "Epoch 640/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4325 - val_loss: 47.5764\n",
      "Epoch 641/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4516 - val_loss: 47.6072\n",
      "Epoch 642/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4640 - val_loss: 47.5785\n",
      "Epoch 643/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4482 - val_loss: 47.5295\n",
      "Epoch 644/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4682 - val_loss: 47.5172\n",
      "Epoch 645/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4713 - val_loss: 47.5782\n",
      "Epoch 646/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4367 - val_loss: 47.5106\n",
      "Epoch 647/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4705 - val_loss: 47.5276\n",
      "Epoch 648/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4430 - val_loss: 47.5426\n",
      "Epoch 649/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5022 - val_loss: 47.6097\n",
      "Epoch 650/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.4686 - val_loss: 47.5140\n",
      "Epoch 651/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.3917 - val_loss: 47.5738\n",
      "Epoch 652/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4548 - val_loss: 47.5555\n",
      "Epoch 653/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4037 - val_loss: 47.5163\n",
      "Epoch 654/1000\n",
      "450/450 [==============================] - 0s 40us/step - loss: 44.4850 - val_loss: 47.5189\n",
      "Epoch 655/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5193 - val_loss: 47.6931\n",
      "Epoch 656/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4571 - val_loss: 47.5248\n",
      "Epoch 657/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4420 - val_loss: 47.5137\n",
      "Epoch 658/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4140 - val_loss: 47.6124\n",
      "Epoch 659/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5178 - val_loss: 47.6655\n",
      "Epoch 660/1000\n",
      "450/450 [==============================] - 0s 31us/step - loss: 44.4622 - val_loss: 47.5668\n",
      "Epoch 661/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4455 - val_loss: 47.6166\n",
      "Epoch 662/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.5016 - val_loss: 47.6035\n",
      "Epoch 663/1000\n",
      "450/450 [==============================] - 0s 45us/step - loss: 44.4136 - val_loss: 47.5133\n",
      "Epoch 664/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4722 - val_loss: 47.5775\n",
      "Epoch 665/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.4343 - val_loss: 47.5428\n",
      "Epoch 666/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4235 - val_loss: 47.5139\n",
      "Epoch 667/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.5641 - val_loss: 47.5448\n",
      "Epoch 668/1000\n",
      "450/450 [==============================] - 0s 40us/step - loss: 44.5520 - val_loss: 47.5300\n",
      "Epoch 669/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.4792 - val_loss: 47.5163\n",
      "Epoch 670/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.4455 - val_loss: 47.5569\n",
      "Epoch 671/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.4333 - val_loss: 47.6050\n",
      "Epoch 672/1000\n",
      "450/450 [==============================] - 0s 41us/step - loss: 44.5236 - val_loss: 47.5743\n",
      "Epoch 673/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4063 - val_loss: 47.5110\n",
      "Epoch 674/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4545 - val_loss: 47.5491\n",
      "Epoch 675/1000\n",
      "450/450 [==============================] - 0s 32us/step - loss: 44.4475 - val_loss: 47.5627\n",
      "Epoch 676/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.3886 - val_loss: 47.5141\n",
      "Epoch 677/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4559 - val_loss: 47.5177\n",
      "Epoch 678/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4438 - val_loss: 47.5496\n",
      "Epoch 679/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4261 - val_loss: 47.5588\n",
      "Epoch 680/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4259 - val_loss: 47.5406\n",
      "Epoch 681/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4373 - val_loss: 47.5456\n",
      "Epoch 682/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4740 - val_loss: 47.6107\n",
      "Epoch 683/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4101 - val_loss: 47.5154\n",
      "Epoch 684/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4620 - val_loss: 47.5151\n",
      "Epoch 685/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.5358 - val_loss: 47.5847\n",
      "Epoch 686/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4367 - val_loss: 47.5169\n",
      "Epoch 687/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 0s 38us/step - loss: 44.5825 - val_loss: 47.5184\n",
      "Epoch 688/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4942 - val_loss: 47.6649\n",
      "Epoch 689/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4572 - val_loss: 47.5392\n",
      "Epoch 690/1000\n",
      "450/450 [==============================] - 0s 40us/step - loss: 44.4884 - val_loss: 47.5188\n",
      "Epoch 691/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4092 - val_loss: 47.5902\n",
      "Epoch 692/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4528 - val_loss: 47.5599\n",
      "Epoch 693/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4448 - val_loss: 47.5176\n",
      "Epoch 694/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4399 - val_loss: 47.5590\n",
      "Epoch 695/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4291 - val_loss: 47.6043\n",
      "Epoch 696/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4547 - val_loss: 47.5593\n",
      "Epoch 697/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4783 - val_loss: 47.5203\n",
      "Epoch 698/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4621 - val_loss: 47.5123\n",
      "Epoch 699/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4574 - val_loss: 47.5347\n",
      "Epoch 700/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.6040 - val_loss: 47.5479\n",
      "Epoch 701/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5043 - val_loss: 47.5202\n",
      "Epoch 702/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.5141 - val_loss: 47.5175\n",
      "Epoch 703/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4438 - val_loss: 47.5504\n",
      "Epoch 704/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4528 - val_loss: 47.6888\n",
      "Epoch 705/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4773 - val_loss: 47.5619\n",
      "Epoch 706/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4436 - val_loss: 47.5740\n",
      "Epoch 707/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4316 - val_loss: 47.5243\n",
      "Epoch 708/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4665 - val_loss: 47.5268\n",
      "Epoch 709/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4791 - val_loss: 47.5201\n",
      "Epoch 710/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4296 - val_loss: 47.5618\n",
      "Epoch 711/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4623 - val_loss: 47.5808\n",
      "Epoch 712/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4257 - val_loss: 47.5206\n",
      "Epoch 713/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5325 - val_loss: 47.5408\n",
      "Epoch 714/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4919 - val_loss: 47.5114\n",
      "Epoch 715/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.4753 - val_loss: 47.5121\n",
      "Epoch 716/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.4708 - val_loss: 47.5209\n",
      "Epoch 717/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4191 - val_loss: 47.5690\n",
      "Epoch 718/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4311 - val_loss: 47.5159\n",
      "Epoch 719/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4852 - val_loss: 47.5333\n",
      "Epoch 720/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4405 - val_loss: 47.7020\n",
      "Epoch 721/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4680 - val_loss: 47.5846\n",
      "Epoch 722/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4368 - val_loss: 47.5174\n",
      "Epoch 723/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4240 - val_loss: 47.5160\n",
      "Epoch 724/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4728 - val_loss: 47.5110\n",
      "Epoch 725/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4793 - val_loss: 47.5518\n",
      "Epoch 726/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4572 - val_loss: 47.6386\n",
      "Epoch 727/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4509 - val_loss: 47.5296\n",
      "Epoch 728/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4524 - val_loss: 47.5252\n",
      "Epoch 729/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.5683 - val_loss: 47.5159\n",
      "Epoch 730/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4155 - val_loss: 47.6609\n",
      "Epoch 731/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.5597 - val_loss: 47.6776\n",
      "Epoch 732/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4464 - val_loss: 47.5493\n",
      "Epoch 733/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4349 - val_loss: 47.5209\n",
      "Epoch 734/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4242 - val_loss: 47.5169\n",
      "Epoch 735/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4540 - val_loss: 47.5137\n",
      "Epoch 736/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.5398 - val_loss: 47.5718\n",
      "Epoch 737/1000\n",
      "450/450 [==============================] - 0s 41us/step - loss: 44.4384 - val_loss: 47.5165\n",
      "Epoch 738/1000\n",
      "450/450 [==============================] - 0s 41us/step - loss: 44.5655 - val_loss: 47.5247\n",
      "Epoch 739/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.4307 - val_loss: 47.5663\n",
      "Epoch 740/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4404 - val_loss: 47.5186\n",
      "Epoch 741/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4401 - val_loss: 47.5159\n",
      "Epoch 742/1000\n",
      "450/450 [==============================] - 0s 40us/step - loss: 44.4352 - val_loss: 47.5193\n",
      "Epoch 743/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4550 - val_loss: 47.5101\n",
      "Epoch 744/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4575 - val_loss: 47.5288\n",
      "Epoch 745/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.5161 - val_loss: 47.5319\n",
      "Epoch 746/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.5027 - val_loss: 47.5150\n",
      "Epoch 747/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4576 - val_loss: 47.5174\n",
      "Epoch 748/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4614 - val_loss: 47.5292\n",
      "Epoch 749/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4564 - val_loss: 47.5935\n",
      "Epoch 750/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4488 - val_loss: 47.6667\n",
      "Epoch 751/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5330 - val_loss: 47.6467\n",
      "Epoch 752/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4758 - val_loss: 47.5383\n",
      "Epoch 753/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4363 - val_loss: 47.5986\n",
      "Epoch 754/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4854 - val_loss: 47.7064\n",
      "Epoch 755/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.5242 - val_loss: 47.6175\n",
      "Epoch 756/1000\n",
      "450/450 [==============================] - 0s 43us/step - loss: 44.4265 - val_loss: 47.5415\n",
      "Epoch 757/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4242 - val_loss: 47.5298\n",
      "Epoch 758/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4721 - val_loss: 47.5732\n",
      "Epoch 759/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4480 - val_loss: 47.5814\n",
      "Epoch 760/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4557 - val_loss: 47.5380\n",
      "Epoch 761/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4553 - val_loss: 47.5106\n",
      "Epoch 762/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4647 - val_loss: 47.5432\n",
      "Epoch 763/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 0s 36us/step - loss: 44.4412 - val_loss: 47.6106\n",
      "Epoch 764/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4766 - val_loss: 47.6105\n",
      "Epoch 765/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4570 - val_loss: 47.5467\n",
      "Epoch 766/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4716 - val_loss: 47.5179\n",
      "Epoch 767/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4878 - val_loss: 47.5151\n",
      "Epoch 768/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4659 - val_loss: 47.5109\n",
      "Epoch 769/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4514 - val_loss: 47.5119\n",
      "Epoch 770/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5719 - val_loss: 47.5164\n",
      "Epoch 771/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4705 - val_loss: 47.5916\n",
      "Epoch 772/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4171 - val_loss: 47.5123\n",
      "Epoch 773/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5218 - val_loss: 47.5171\n",
      "Epoch 774/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4309 - val_loss: 47.5884\n",
      "Epoch 775/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4711 - val_loss: 47.5822\n",
      "Epoch 776/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4382 - val_loss: 47.5254\n",
      "Epoch 777/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4444 - val_loss: 47.5130\n",
      "Epoch 778/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4641 - val_loss: 47.5747\n",
      "Epoch 779/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4509 - val_loss: 47.5112\n",
      "Epoch 780/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4483 - val_loss: 47.5142\n",
      "Epoch 781/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4688 - val_loss: 47.5458\n",
      "Epoch 782/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4578 - val_loss: 47.5288\n",
      "Epoch 783/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4271 - val_loss: 47.5644\n",
      "Epoch 784/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5005 - val_loss: 47.6709\n",
      "Epoch 785/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4516 - val_loss: 47.5516\n",
      "Epoch 786/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4628 - val_loss: 47.5251\n",
      "Epoch 787/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4396 - val_loss: 47.5534\n",
      "Epoch 788/1000\n",
      "450/450 [==============================] - 0s 40us/step - loss: 44.4456 - val_loss: 47.6307\n",
      "Epoch 789/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4422 - val_loss: 47.5466\n",
      "Epoch 790/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4978 - val_loss: 47.5359\n",
      "Epoch 791/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5384 - val_loss: 47.5392\n",
      "Epoch 792/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4669 - val_loss: 47.5152\n",
      "Epoch 793/1000\n",
      "450/450 [==============================] - 0s 42us/step - loss: 44.4760 - val_loss: 47.5342\n",
      "Epoch 794/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4389 - val_loss: 47.5142\n",
      "Epoch 795/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4643 - val_loss: 47.5124\n",
      "Epoch 796/1000\n",
      "450/450 [==============================] - 0s 31us/step - loss: 44.4941 - val_loss: 47.5186\n",
      "Epoch 797/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4523 - val_loss: 47.5183\n",
      "Epoch 798/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4414 - val_loss: 47.5471\n",
      "Epoch 799/1000\n",
      "450/450 [==============================] - 0s 40us/step - loss: 44.5200 - val_loss: 47.5663\n",
      "Epoch 800/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4862 - val_loss: 47.5130\n",
      "Epoch 801/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4323 - val_loss: 47.5452\n",
      "Epoch 802/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4769 - val_loss: 47.6309\n",
      "Epoch 803/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4468 - val_loss: 47.5169\n",
      "Epoch 804/1000\n",
      "450/450 [==============================] - 0s 32us/step - loss: 44.4468 - val_loss: 47.5231\n",
      "Epoch 805/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4347 - val_loss: 47.5424\n",
      "Epoch 806/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4411 - val_loss: 47.5769\n",
      "Epoch 807/1000\n",
      "450/450 [==============================] - 0s 41us/step - loss: 44.5039 - val_loss: 47.5108\n",
      "Epoch 808/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4375 - val_loss: 47.5387\n",
      "Epoch 809/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.5828 - val_loss: 47.6625\n",
      "Epoch 810/1000\n",
      "450/450 [==============================] - 0s 32us/step - loss: 44.3949 - val_loss: 47.5107\n",
      "Epoch 811/1000\n",
      "450/450 [==============================] - 0s 32us/step - loss: 44.5813 - val_loss: 47.5859\n",
      "Epoch 812/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.5835 - val_loss: 47.5388\n",
      "Epoch 813/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4513 - val_loss: 47.5222\n",
      "Epoch 814/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4146 - val_loss: 47.5725\n",
      "Epoch 815/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4622 - val_loss: 47.5407\n",
      "Epoch 816/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5442 - val_loss: 47.5229\n",
      "Epoch 817/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4693 - val_loss: 47.5404\n",
      "Epoch 818/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4972 - val_loss: 47.5837\n",
      "Epoch 819/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4422 - val_loss: 47.5171\n",
      "Epoch 820/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4808 - val_loss: 47.5762\n",
      "Epoch 821/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4715 - val_loss: 47.5101\n",
      "Epoch 822/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4715 - val_loss: 47.5166\n",
      "Epoch 823/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4782 - val_loss: 47.5187\n",
      "Epoch 824/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.4429 - val_loss: 47.5181\n",
      "Epoch 825/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4779 - val_loss: 47.5890\n",
      "Epoch 826/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4399 - val_loss: 47.5769\n",
      "Epoch 827/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4521 - val_loss: 47.5691\n",
      "Epoch 828/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4324 - val_loss: 47.5167\n",
      "Epoch 829/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4484 - val_loss: 47.5292\n",
      "Epoch 830/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4266 - val_loss: 47.5118\n",
      "Epoch 831/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5227 - val_loss: 47.5241\n",
      "Epoch 832/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4638 - val_loss: 47.5162\n",
      "Epoch 833/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4914 - val_loss: 47.5173\n",
      "Epoch 834/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4578 - val_loss: 47.5287\n",
      "Epoch 835/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4276 - val_loss: 47.5560\n",
      "Epoch 836/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5223 - val_loss: 47.6092\n",
      "Epoch 837/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4108 - val_loss: 47.5134\n",
      "Epoch 838/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4496 - val_loss: 47.5170\n",
      "Epoch 839/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 0s 35us/step - loss: 44.4377 - val_loss: 47.5304\n",
      "Epoch 840/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4327 - val_loss: 47.5168\n",
      "Epoch 841/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.4235 - val_loss: 47.5236\n",
      "Epoch 842/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5928 - val_loss: 47.5286\n",
      "Epoch 843/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4339 - val_loss: 47.6341\n",
      "Epoch 844/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4917 - val_loss: 47.6756\n",
      "Epoch 845/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4501 - val_loss: 47.5479\n",
      "Epoch 846/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4889 - val_loss: 47.5293\n",
      "Epoch 847/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4649 - val_loss: 47.5163\n",
      "Epoch 848/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5655 - val_loss: 47.5182\n",
      "Epoch 849/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4334 - val_loss: 47.6024\n",
      "Epoch 850/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4873 - val_loss: 47.6176\n",
      "Epoch 851/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4535 - val_loss: 47.5204\n",
      "Epoch 852/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4310 - val_loss: 47.5427\n",
      "Epoch 853/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4154 - val_loss: 47.6045\n",
      "Epoch 854/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4409 - val_loss: 47.6117\n",
      "Epoch 855/1000\n",
      "450/450 [==============================] - 0s 32us/step - loss: 44.4836 - val_loss: 47.6050\n",
      "Epoch 856/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4090 - val_loss: 47.5176\n",
      "Epoch 857/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4223 - val_loss: 47.5575\n",
      "Epoch 858/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4412 - val_loss: 47.5694\n",
      "Epoch 859/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4291 - val_loss: 47.5944\n",
      "Epoch 860/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5079 - val_loss: 47.6851\n",
      "Epoch 861/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.5223 - val_loss: 47.6425\n",
      "Epoch 862/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4668 - val_loss: 47.5533\n",
      "Epoch 863/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4456 - val_loss: 47.6267\n",
      "Epoch 864/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4521 - val_loss: 47.6033\n",
      "Epoch 865/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4722 - val_loss: 47.5522\n",
      "Epoch 866/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4301 - val_loss: 47.5224\n",
      "Epoch 867/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4340 - val_loss: 47.5193\n",
      "Epoch 868/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4282 - val_loss: 47.5195\n",
      "Epoch 869/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4259 - val_loss: 47.5157\n",
      "Epoch 870/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4951 - val_loss: 47.5205\n",
      "Epoch 871/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4712 - val_loss: 47.5231\n",
      "Epoch 872/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4404 - val_loss: 47.5368\n",
      "Epoch 873/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4394 - val_loss: 47.5318\n",
      "Epoch 874/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4382 - val_loss: 47.5820\n",
      "Epoch 875/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4890 - val_loss: 47.6186\n",
      "Epoch 876/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4491 - val_loss: 47.5794\n",
      "Epoch 877/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4502 - val_loss: 47.5818\n",
      "Epoch 878/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4162 - val_loss: 47.5175\n",
      "Epoch 879/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4582 - val_loss: 47.5128\n",
      "Epoch 880/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.5293 - val_loss: 47.5173\n",
      "Epoch 881/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4223 - val_loss: 47.5533\n",
      "Epoch 882/1000\n",
      "450/450 [==============================] - 0s 32us/step - loss: 44.5122 - val_loss: 47.7409\n",
      "Epoch 883/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.5679 - val_loss: 47.6391\n",
      "Epoch 884/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4281 - val_loss: 47.5424\n",
      "Epoch 885/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4524 - val_loss: 47.5223\n",
      "Epoch 886/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4337 - val_loss: 47.5317\n",
      "Epoch 887/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4537 - val_loss: 47.5177\n",
      "Epoch 888/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4167 - val_loss: 47.5957\n",
      "Epoch 889/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4642 - val_loss: 47.6852\n",
      "Epoch 890/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4895 - val_loss: 47.5361\n",
      "Epoch 891/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4402 - val_loss: 47.5116\n",
      "Epoch 892/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4521 - val_loss: 47.5150\n",
      "Epoch 893/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4533 - val_loss: 47.5159\n",
      "Epoch 894/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4015 - val_loss: 47.5958\n",
      "Epoch 895/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4555 - val_loss: 47.7287\n",
      "Epoch 896/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.5235 - val_loss: 47.6518\n",
      "Epoch 897/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4455 - val_loss: 47.5727\n",
      "Epoch 898/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4241 - val_loss: 47.5182\n",
      "Epoch 899/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4390 - val_loss: 47.5138\n",
      "Epoch 900/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4248 - val_loss: 47.5611\n",
      "Epoch 901/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4401 - val_loss: 47.5455\n",
      "Epoch 902/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4644 - val_loss: 47.5147\n",
      "Epoch 903/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4172 - val_loss: 47.5434\n",
      "Epoch 904/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4315 - val_loss: 47.5169\n",
      "Epoch 905/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4334 - val_loss: 47.5385\n",
      "Epoch 906/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4914 - val_loss: 47.5947\n",
      "Epoch 907/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4425 - val_loss: 47.5118\n",
      "Epoch 908/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4634 - val_loss: 47.5112\n",
      "Epoch 909/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5151 - val_loss: 47.5134\n",
      "Epoch 910/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.3932 - val_loss: 47.5631\n",
      "Epoch 911/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4509 - val_loss: 47.5732\n",
      "Epoch 912/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4091 - val_loss: 47.5121\n",
      "Epoch 913/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4510 - val_loss: 47.5245\n",
      "Epoch 914/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4692 - val_loss: 47.5108\n",
      "Epoch 915/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 0s 35us/step - loss: 44.4461 - val_loss: 47.5179\n",
      "Epoch 916/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4328 - val_loss: 47.5411\n",
      "Epoch 917/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4308 - val_loss: 47.5477\n",
      "Epoch 918/1000\n",
      "450/450 [==============================] - 0s 32us/step - loss: 44.5157 - val_loss: 47.5141\n",
      "Epoch 919/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4224 - val_loss: 47.5652\n",
      "Epoch 920/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4199 - val_loss: 47.5147\n",
      "Epoch 921/1000\n",
      "450/450 [==============================] - 0s 32us/step - loss: 44.4760 - val_loss: 47.5251\n",
      "Epoch 922/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4784 - val_loss: 47.5164\n",
      "Epoch 923/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4270 - val_loss: 47.6066\n",
      "Epoch 924/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4873 - val_loss: 47.7378\n",
      "Epoch 925/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.5347 - val_loss: 47.6463\n",
      "Epoch 926/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4388 - val_loss: 47.5372\n",
      "Epoch 927/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4588 - val_loss: 47.5262\n",
      "Epoch 928/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5264 - val_loss: 47.5393\n",
      "Epoch 929/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.5037 - val_loss: 47.5199\n",
      "Epoch 930/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4491 - val_loss: 47.5640\n",
      "Epoch 931/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4266 - val_loss: 47.6358\n",
      "Epoch 932/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.5169 - val_loss: 47.6444\n",
      "Epoch 933/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4601 - val_loss: 47.5391\n",
      "Epoch 934/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4305 - val_loss: 47.5216\n",
      "Epoch 935/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4810 - val_loss: 47.5304\n",
      "Epoch 936/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4151 - val_loss: 47.5736\n",
      "Epoch 937/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4411 - val_loss: 47.5205\n",
      "Epoch 938/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4422 - val_loss: 47.5515\n",
      "Epoch 939/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4351 - val_loss: 47.6066\n",
      "Epoch 940/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.4399 - val_loss: 47.5227\n",
      "Epoch 941/1000\n",
      "450/450 [==============================] - 0s 41us/step - loss: 44.4251 - val_loss: 47.5210\n",
      "Epoch 942/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4501 - val_loss: 47.5210\n",
      "Epoch 943/1000\n",
      "450/450 [==============================] - 0s 39us/step - loss: 44.4712 - val_loss: 47.5687\n",
      "Epoch 944/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4499 - val_loss: 47.5933\n",
      "Epoch 945/1000\n",
      "450/450 [==============================] - 0s 38us/step - loss: 44.4931 - val_loss: 47.7011\n",
      "Epoch 946/1000\n",
      "450/450 [==============================] - 0s 40us/step - loss: 44.4944 - val_loss: 47.6039\n",
      "Epoch 947/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4127 - val_loss: 47.5172\n",
      "Epoch 948/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4566 - val_loss: 47.5177\n",
      "Epoch 949/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4642 - val_loss: 47.5226\n",
      "Epoch 950/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4821 - val_loss: 47.5356\n",
      "Epoch 951/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4787 - val_loss: 47.5163\n",
      "Epoch 952/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4249 - val_loss: 47.5467\n",
      "Epoch 953/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4655 - val_loss: 47.5944\n",
      "Epoch 954/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4282 - val_loss: 47.5316\n",
      "Epoch 955/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4499 - val_loss: 47.5618\n",
      "Epoch 956/1000\n",
      "450/450 [==============================] - 0s 37us/step - loss: 44.4166 - val_loss: 47.5187\n",
      "Epoch 957/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4615 - val_loss: 47.5206\n",
      "Epoch 958/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.5477 - val_loss: 47.5416\n",
      "Epoch 959/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4791 - val_loss: 47.5282\n",
      "Epoch 960/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4255 - val_loss: 47.5439\n",
      "Epoch 961/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4268 - val_loss: 47.5449\n",
      "Epoch 962/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4465 - val_loss: 47.5431\n",
      "Epoch 963/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4138 - val_loss: 47.5723\n",
      "Epoch 964/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4357 - val_loss: 47.5654\n",
      "Epoch 965/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4453 - val_loss: 47.5627\n",
      "Epoch 966/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4302 - val_loss: 47.5209\n",
      "Epoch 967/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4502 - val_loss: 47.5286\n",
      "Epoch 968/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4934 - val_loss: 47.5381\n",
      "Epoch 969/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4846 - val_loss: 47.5160\n",
      "Epoch 970/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4373 - val_loss: 47.5239\n",
      "Epoch 971/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4373 - val_loss: 47.5312\n",
      "Epoch 972/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4386 - val_loss: 47.5473\n",
      "Epoch 973/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4292 - val_loss: 47.5163\n",
      "Epoch 974/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4553 - val_loss: 47.5323\n",
      "Epoch 975/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4366 - val_loss: 47.5493\n",
      "Epoch 976/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4546 - val_loss: 47.6100\n",
      "Epoch 977/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4473 - val_loss: 47.5782\n",
      "Epoch 978/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4346 - val_loss: 47.5441\n",
      "Epoch 979/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4389 - val_loss: 47.5468\n",
      "Epoch 980/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4256 - val_loss: 47.5326\n",
      "Epoch 981/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4265 - val_loss: 47.5281\n",
      "Epoch 982/1000\n",
      "450/450 [==============================] - 0s 32us/step - loss: 44.4329 - val_loss: 47.5516\n",
      "Epoch 983/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4911 - val_loss: 47.6227\n",
      "Epoch 984/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4239 - val_loss: 47.5407\n",
      "Epoch 985/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4512 - val_loss: 47.5186\n",
      "Epoch 986/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4565 - val_loss: 47.5354\n",
      "Epoch 987/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4423 - val_loss: 47.5447\n",
      "Epoch 988/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4446 - val_loss: 47.5990\n",
      "Epoch 989/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4340 - val_loss: 47.5212\n",
      "Epoch 990/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4402 - val_loss: 47.5225\n",
      "Epoch 991/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 0s 36us/step - loss: 44.4521 - val_loss: 47.5199\n",
      "Epoch 992/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4253 - val_loss: 47.5349\n",
      "Epoch 993/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4250 - val_loss: 47.5200\n",
      "Epoch 994/1000\n",
      "450/450 [==============================] - 0s 34us/step - loss: 44.4270 - val_loss: 47.5354\n",
      "Epoch 995/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.4436 - val_loss: 47.5353\n",
      "Epoch 996/1000\n",
      "450/450 [==============================] - 0s 35us/step - loss: 44.5246 - val_loss: 47.5359\n",
      "Epoch 997/1000\n",
      "450/450 [==============================] - 0s 33us/step - loss: 44.4947 - val_loss: 47.5136\n",
      "Epoch 998/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4758 - val_loss: 47.5557\n",
      "Epoch 999/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4221 - val_loss: 47.5205\n",
      "Epoch 1000/1000\n",
      "450/450 [==============================] - 0s 36us/step - loss: 44.4387 - val_loss: 47.5220\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainX, trainY, validation_data=(testX, testY),epochs=1000, \n",
    "                    batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 44.419, Test: 47.522\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "train_mse = model.evaluate(trainX, trainY, verbose=0)\n",
    "test_mse = model.evaluate(testX, testY, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(13, 5))\n",
    "axes[0].plot(history.history['loss'])\n",
    "axes[1].plot(history.history['val_loss'])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions for training\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "train_predict = [i for i in trainPredict]\n",
    "test_predict = [i for i in testPredict]\n",
    "prediction = train_predict + test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbe39ea6c10>]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
